{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f00e9dd",
   "metadata": {},
   "source": [
    "## Load Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66e2c3f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Post-training Optimization Tool is deprecated and will be removed in the future. Please use Neural Network Compression Framework instead: https://github.com/openvinotoolkit/nncf\n",
      "Nevergrad package could not be imported. If you are planning to use any hyperparameter optimization algo, consider installing it using pip. This implies advanced usage of the tool. Note that nevergrad is compatible only with Python 3.7+\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "from pruna.algorithms.smasher_config import SmasherConfig\n",
    "from pruna.smash import smash\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('facebook/opt-125m')\n",
    "model = AutoModelForCausalLM.from_pretrained('facebook/opt-125m', trust_remote_code=True, torch_dtype=\"auto\")\n",
    "model.to('cuda')\n",
    "ins = tokenizer(\"What are we having for dinner?\", return_tensors=\"pt\", truncation=True).to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a491950b",
   "metadata": {},
   "source": [
    "## Smash it!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5913199",
   "metadata": {},
   "source": [
    "### Define Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b6a3bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "smasher_config = SmasherConfig()\n",
    "smasher_config['compiler'] = 'ctranslate2_generation'\n",
    "smasher_config['n_quantization_bits'] = 16\n",
    "smasher_config['tokenizer_name'] = tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb79e95",
   "metadata": {},
   "source": [
    "### Smash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47c05a6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ WARNING ] Found cached dataset parquet (/nfs/homedirs/rachwan/.cache/huggingface/datasets/Polyglot-or-Not___parquet/Polyglot-or-Not--Fact-Completion-bf9cfaebc2874386/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Compile...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success.\n"
     ]
    }
   ],
   "source": [
    "smashed_model = smash(\n",
    "        model=model,\n",
    "        data_module=\"Polyglot_1000\",\n",
    "        api_key='your-api-key',\n",
    "        model_config=None,\n",
    "        smasher_config=smasher_config,\n",
    "        device='cuda',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8909d712",
   "metadata": {},
   "source": [
    "## Base Model Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a09b3a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.11 s, sys: 18.7 ms, total: 1.13 s\n",
      "Wall time: 1.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = model.generate(**ins, max_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aac13807",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tokenizer.decode(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1a5a3d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"</s>What are we having for dinner?\\nA nice dinner with a friend.\\nI'm not sure what to do with the rest of the night.\\nI'm going to have to go to bed.\\nI'm going to have to go\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e20052",
   "metadata": {},
   "source": [
    "## Smashed Model Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3a94dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 141 ms, sys: 40.2 ms, total: 181 ms\n",
      "Wall time: 180 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = smashed_model(ins, max_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42a15f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tokenizer.decode(results[0].sequences_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7fe918c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What are we having for dinner?\\nA nice dinner with a friend.\\nI'm not sure what to do with the rest of the night.\\nI'm going to have to go to bed.\\nI'm going to have to go to\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
